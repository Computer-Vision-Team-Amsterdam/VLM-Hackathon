{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Use the VLM endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pyheif\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from openai import AzureOpenAI, ChatCompletion\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "# Function to encode an image\n",
    "def encode_image(image_path: str):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Function to encode and resize an image\n",
    "def encode_and_resize(image_path: str, max_size: int = 640):\n",
    "    if image_path.endswith(\".HEIC\"):\n",
    "        img = read_heic_to_numpy(image_path)\n",
    "    else:\n",
    "        img = cv2.imread(image_path)\n",
    "    scale_factor = max_size / max(img.shape)\n",
    "    img = cv2.resize(img, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)\n",
    "    _, im_arr = cv2.imencode('.jpg', img)  # im_arr: image in Numpy one-dim array format.\n",
    "    im_bytes = im_arr.tobytes()\n",
    "    return base64.b64encode(im_bytes).decode(\"utf-8\")\n",
    "\n",
    "# Function to read .HEIC image format\n",
    "def read_heic_to_numpy(file_path: str):\n",
    "    heif_file = pyheif.read(file_path)\n",
    "    data = heif_file.data\n",
    "    if heif_file.mode == \"RGB\":\n",
    "        numpy_array = np.frombuffer(data, dtype=np.uint8).reshape(\n",
    "            heif_file.size[1], heif_file.size[0], 3)\n",
    "    elif heif_file.mode == \"RGBA\":\n",
    "        numpy_array = np.frombuffer(data, dtype=np.uint8).reshape(\n",
    "            heif_file.size[1], heif_file.size[0], 4)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported HEIC color mode\")\n",
    "    return numpy_array\n",
    "\n",
    "\n",
    "endpoint = \"https://oai-aip-cv-ont-sdc.openai.azure.com/\"\n",
    "model_name = \"gpt-4o\"\n",
    "deployment = \"gpt-4o\"\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "api_version = \"2024-12-01-preview\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    azure_ad_token_provider=token_provider,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(system_prompt: str, user_prompt: str, image_path: Optional[str] = None, detail: str = \"low\") -> ChatCompletion:\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_prompt\n",
    "    }\n",
    "\n",
    "    user_content = [\n",
    "        { \"type\": \"text\", \"text\": user_prompt }\n",
    "    ]\n",
    "    if image_path is not None:\n",
    "        base64_image = encode_and_resize(image_path)\n",
    "        user_content.append(\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    \"detail\": detail, # reduces token usage\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_content\n",
    "    }\n",
    "\n",
    "    messages = [\n",
    "        system_message,\n",
    "        user_message,\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        max_tokens=4096,\n",
    "        temperature=0.0,\n",
    "        model=deployment\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Ask question with a photo as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Je bent een AI-assistent die foto's van de openbare ruimte beoordeelt op basis van de CROW-systematiek gericht op voetgangersveiligheid, met een focus op struikelgevaar. Analyseer de foto op de volgende aspecten:\n",
    "\n",
    "1. **Oneffenheden in het oppervlak**: Identificeer hoogteverschillen, losse of middende elementen in de verharding, of gaten.\n",
    "2. **Continuïteit van het loopvlak**: Controleer of het loopvlak onderbroken wordt en of dit voetgangers dwingt om obstakels te vermijden, uit balans te raken, of ongebruikelijke stappen te zetten.\n",
    "3. **Materiaal en conditie**: Beoordeel materiaalbeschadiging zoals scheuren, verzakkingen, of gladde oppervlakken die struikelrisico’s kunnen verhogen.\n",
    "4. **Omgevingsfactoren**: Houd rekening met omgevingskenmerken zoals slechte verlichting, scherpe bochten of verwaarloosde plekken die risico's kunnen verergeren.  \n",
    "\n",
    "Geef een prioriteitsscore:  \n",
    "- **Laag** risico: Klein of verwaarloosbaar struikelgevaar, interventie kan wachten. Dit is bijvoorbeeld het geval wanneer de oneffenheid kleiner is dan 1cm.\n",
    "- **Middel** risico: Aandacht vereist, plan remedie op middellange termijn. Dit is bijvoorbeeld het geval wanneer de oneffenheid tussen de 1cm en 3cm is.\n",
    "- **Hoog** risico: Directe actie noodzakelijk vanwege significante kans op letsel. Dit is bijvoorbeeld het geval wanneer de oneffenheid groter is dan 3cm.\n",
    "\n",
    "Formatteer je analyse als een inspectierapport.\n",
    "\n",
    "Inspectierapport\n",
    "---\n",
    "**Omschrijving van het probleem:** [Beknopte omschrijving van het belangrijkste probleem, bijvoorbeeld \"Losliggende tegel\", \"Boomwortelschade\", \"Gat\"].\n",
    "**Omgevingsfactoren:** [Bijv. Slecht zicht, aanwezige obstakels, weersinvloed]\n",
    "**Hoogteverschil:** [Schatting van het hoogteverschil in cm]\n",
    "**Beoordeling van risico:** {Laag, Middel, Hoog}\n",
    "**Toelichting:** [Geef een beknopte technische verklaring voor de risico score, gebruikmakend van je analyse. Refereer specifieke elementen in de foto. Voorbeeld: \"De foto toont een losliggende stoeptegel in het midden van de looproute. De oneffenheid is groter dan 3cm en valt dus onder hoog risico.\"] \n",
    "---\n",
    "\n",
    "Als er geen duidelijk risico zichtbaar is, geef dan \"Geen significant risico\" als **Omschrijving van het probleem** en geef als prioriteit \"Laag\".\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = \"\"\"\n",
    "Genereer een inspectierapport voor deze foto.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# images_folder = \"../datasets/experiments/onderhoud/Collection/\"  # See other notebook on how to download an image from blob store\n",
    "# image_name = \"IMG_1182.HEIC\"\n",
    "\n",
    "images_folder = \"../datasets/experiments/onderhoud/2025_Centrum/Foto's klein onderhoud/\"\n",
    "image_name = \"59ef2cf7-b13c-4f9e-8878-9752e015cb56.jpeg\"\n",
    "\n",
    "response = prompt(SYSTEM_PROMPT, USER_PROMPT, image_path=os.path.join(images_folder, image_name), detail=\"high\")\n",
    "\n",
    "text = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(text.replace(\"/n\", \"<br>\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## GPT prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Je bent een AI hulpmiddel dat de Gemeente Amsterdam ondersteunt bij het analyseren van foto's in de openbare ruimte. \n",
    "Je specifieke doel is om struikelgevaar voor voetgangers te beoordelen op basis van de CROW-systematiek voor wegbeheer.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = \"\"\"\n",
    "Geef een system prompt die geschikt is om foto's te beoordelen op basis van de CROW methodiek, specifiek toegespitst op struikelgevaar. \n",
    "Gebruik CROW elementen in de prompt en zorg dat het antwoord een prioriteit score bevat van {laag, middel, hoog} gebaseerd op het risico.\n",
    "Geef ook een indicatie van de termijn waarop het probleem verholpen moeten worden. Oneffenheden van meer dan 3cm zijn urgent.\n",
    "De output moet geformateerd worden als inspectierapport.\n",
    "\"\"\"\n",
    "\n",
    "response = prompt(SYSTEM_PROMPT, USER_PROMPT)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Extract description and risk from response and generate a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "val_df = pd.read_csv(\"../datasets/experiments/onderhoud/2025_Centrum/validatieset.csv\", sep=\";\")\n",
    "images_folder = \"../datasets/experiments/onderhoud/2025_Centrum/validatie/\"\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"foto\": [],\n",
    "    \"omschrijving\": [],\n",
    "    \"risico\": []\n",
    "}\n",
    "\n",
    "for _, row in val_df.iterrows():\n",
    "    print(f\"Processing {row['fotonummer']}\")\n",
    "    image_path = os.path.join(images_folder, row[\"fotonummer\"])\n",
    "    \n",
    "    response = prompt(SYSTEM_PROMPT, USER_PROMPT, image_path)\n",
    "\n",
    "    result: str = response.choices[0].message.content\n",
    "    risico = result.partition(\"**Beoordeling van risico:**\")[2].partition(\"**Toelichting:**\")[0].strip().strip(\"*\")\n",
    "    omschrijving = result.partition(\"**Omschrijving van het probleem:**\")[2].partition(\"**Omgevingsfactoren:**\")[0].strip().strip(\"*\")\n",
    "\n",
    "    data[\"foto\"].append(row[\"fotonummer\"])\n",
    "    data[\"omschrijving\"].append(omschrijving)\n",
    "    data[\"risico\"].append(risico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Run model over a bunch of images and generate a PDF with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = \"../datasets/experiments/onderhoud/2025_Centrum/validatie/\"\n",
    "\n",
    "images = os.listdir(images_folder)\n",
    "\n",
    "image_text_pairs = []\n",
    "\n",
    "for img in images:\n",
    "    print(f\"Processing {img}\")\n",
    "    image_path = os.path.join(images_folder, img)\n",
    "    \n",
    "    response = prompt(SYSTEM_PROMPT, USER_PROMPT, image_path, detail=\"high\")\n",
    "\n",
    "    result: str = response.choices[0].message.content\n",
    "    image_text_pairs.append((image_path, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.units import mm\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.platypus import Paragraph, Frame\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.utils import ImageReader\n",
    "import markdown\n",
    "import os\n",
    "\n",
    "def generate_pdf(output_path, image_text_pairs, page_size=A4, margin_mm=20, image_max_height_mm=120):\n",
    "    \"\"\"\n",
    "    Generates a PDF with each page containing a centered image and a text block below it.\n",
    "    \n",
    "    :param output_path: Path where the PDF will be saved.\n",
    "    :param image_text_pairs: List of tuples (image_path, text), each for one page.\n",
    "    :param page_size: Tuple with the page size (default: A4).\n",
    "    :param margin_mm: Margin on each side in mm.\n",
    "    :param image_max_height_mm: Maximum image height in mm.\n",
    "    \"\"\"\n",
    "    c = canvas.Canvas(output_path, pagesize=page_size)\n",
    "    width, height = page_size\n",
    "    margin = margin_mm * mm\n",
    "    image_max_height = image_max_height_mm * mm\n",
    "\n",
    "    styles = getSampleStyleSheet()\n",
    "    text_style = styles['Normal']\n",
    "\n",
    "    for image_path, text in image_text_pairs:\n",
    "        # Draw image centered horizontally\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "        img = ImageReader(image_path)\n",
    "        img_width, img_height = img.getSize()\n",
    "\n",
    "        # Scale image to fit within page margins and max height\n",
    "        available_width = width - 2 * margin\n",
    "        scale = min(available_width / img_width, image_max_height / img_height, 1.0)\n",
    "        draw_width = img_width * scale\n",
    "        draw_height = img_height * scale\n",
    "\n",
    "        x = (width - draw_width) / 2\n",
    "        y = height - margin - draw_height\n",
    "        c.drawImage(image_path, x, y, width=draw_width, height=draw_height)\n",
    "\n",
    "        # Draw text block below image, allowing for newlines in the caption\n",
    "        frame_height = y - margin\n",
    "\n",
    "        # Convert newlines in text to <br/> for Paragraph formatting\n",
    "        html = markdown.markdown(text.replace('\\n', '<br/>'))\n",
    "        paragraph = Paragraph(html, text_style)\n",
    "        frame = Frame(margin, margin, width - 2 * margin, frame_height, showBoundary=0)\n",
    "        frame.addFromList([paragraph], c)\n",
    "\n",
    "        c.showPage()\n",
    "\n",
    "    c.save()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# image_text_pairs = [\n",
    "#     (os.path.join(images_folder, image_name), response.choices[0].message.content),\n",
    "#     (os.path.join(images_folder, image_name), response.choices[0].message.content),\n",
    "# ]\n",
    "generate_pdf(\"rapport.pdf\", image_text_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VLM-Hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

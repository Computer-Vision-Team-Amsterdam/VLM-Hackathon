{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Use the VLM endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pyheif\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "# Function to encode an image\n",
    "def encode_image(image_path: str):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Function to encode and resize an image\n",
    "def encode_and_resize(image_path: str, max_size: int = 640):\n",
    "    if image_path.endswith(\".HEIC\"):\n",
    "        img = read_heic_to_numpy(image_path)\n",
    "    else:\n",
    "        img = cv2.imread(image_path)\n",
    "    scale_factor = max_size / max(img.shape)\n",
    "    img = cv2.resize(img, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)\n",
    "    _, im_arr = cv2.imencode('.jpg', img)  # im_arr: image in Numpy one-dim array format.\n",
    "    im_bytes = im_arr.tobytes()\n",
    "    return base64.b64encode(im_bytes).decode(\"utf-8\")\n",
    "\n",
    "# Function to read .HEIC image format\n",
    "def read_heic_to_numpy(file_path: str):\n",
    "    heif_file = pyheif.read(file_path)\n",
    "    data = heif_file.data\n",
    "    if heif_file.mode == \"RGB\":\n",
    "        numpy_array = np.frombuffer(data, dtype=np.uint8).reshape(\n",
    "            heif_file.size[1], heif_file.size[0], 3)\n",
    "    elif heif_file.mode == \"RGBA\":\n",
    "        numpy_array = np.frombuffer(data, dtype=np.uint8).reshape(\n",
    "            heif_file.size[1], heif_file.size[0], 4)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported HEIC color mode\")\n",
    "    return numpy_array\n",
    "\n",
    "\n",
    "endpoint = \"https://oai-aip-cv-ont-sdc.openai.azure.com/\"\n",
    "model_name = \"gpt-4o-mini\"\n",
    "deployment = \"gpt-4o-mini\"\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "api_version = \"2024-12-01-preview\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    azure_ad_token_provider=token_provider,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Ask question with a photo as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = \"local_data/2025_Centrum/images/\"  # See other notebook on how to download an image from blob store\n",
    "image_name = \"18228489-9471-4aee-bc87-0a8605521007.jpeg\"\n",
    "\n",
    "# Getting the Base64 string\n",
    "# base64_image = encode_image(os.path.join(images_folder, image_name))\n",
    "base64_image = encode_and_resize(os.path.join(images_folder, image_name))\n",
    "\n",
    "# Query endpoint\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a sidewalk inspector for the municipality. Your job is to inspect images taken of sidewalk surfaces and assess their quality and maintenance needs.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"text\", \"text\": \"Describe the quality of the sidewalk in this image.\" },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                        \"detail\": \"low\", # reduces token usage\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=4096,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    model=deployment\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VLM-Hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
